---

# マルチステップ LLM パイプラインにおける

# 「タスク精度 vs 埋め込み距離」実験計画書 😺🦐

---

## 1. 実験の目的・背景 😺🦐

本実験の目的は、マルチステップな LLM パイプラインにおいて「各ステップごとに単純に最強モデルを選ぶ戦略」と「ステップ間の埋め込み距離（表現の相性）とタスク精度の両方を考慮して経路（モデル列）を選ぶ戦略」を比較することにある😺🦐。

直感的には、単一ステップのタスクであれば「そのタスクのスコアが最も高いモデルを選べばよい」が、複数ステップを連鎖させる場合、中間表現の“相性”が全体性能に影響する可能性が高い、という問題意識に基づいている😸🦐。

既存の分析から、LLM の出力埋め込みが「タスク空間」と「モデル空間」の両方の構造を持ち、モデルごと・タスクごとに特徴的な分布を形成することが示唆されているため、この構造を用いてマルチステップパイプラインを設計したときに、どのようなトレードオフが現れるかを検証する😺🦐。

---

## 2. 実験のゴールと仮説 😺🦐

**ゴール** 😺🦐

* 3 ステップの LLM パイプラインに対して、

  * (A) 各ステップの「タスクスコア」のみでモデルを選ぶ **局所最強戦略** と、
  * (B) 「タスクスコア − λ × ステップ間距離」に基づいて経路を選ぶ **ネットワーク最適戦略** を比較する😸🦐。
* 両者の最終タスク性能（例：分類精度）を比較し、さらに「タスクスコア vs 距離」のトレードオフ曲線（パレートフロンティア）を描く😺🦐。

**仮説** 😺🦐

* マルチステップ構成では、各ステップの局所的なタスクスコアだけでモデルを選ぶよりも、

  * ステップ間の出力・入力埋め込み分布の距離（表現の相性）を考慮して経路を選択したほうが、
  * パイプライン全体の最終性能が高くなる、もしくは同等の性能でより小さい距離（滑らかな経路）を実現できる😸🦐。

---

## 3. タスク設計（3ステップパイプライン）😺🦐

### 3.1 全体フロー 😺🦐

入力は「テキスト + 正解ラベル」を持つラベル付きテキスト分類データセットとする（ニュース分類やレビュー感情分類など）😺🦐。

3 ステップのパイプライン構成は以下の通りとする😸🦐。

1. **ステップ1：要点抽出（Extract）** 😺🦐

   * 入力：元のテキスト（記事やレビュー本文）😺🦐。
   * 出力：3〜5 個程度の重要ポイントを bullet で列挙したテキスト😸🦐。

2. **ステップ2：要約生成（Summarize）** 😺🦐

   * 入力：ステップ1の bullet 群😺🦐。
   * 出力：1〜3文程度の自然文要約テキスト😸🦐。

3. **ステップ3：分類（Classify）** 😺🦐

   * 入力：ステップ2の要約テキスト😺🦐。
   * 出力：データセットに対応した分類ラベル（カテゴリや感情ラベルなど）😸🦐。

**最終評価**は、ステップ3で出力されたラベルと正解ラベルの一致率（分類精度）で行う😺🦐。

---

## 4. データセット選定方針 😺🦐

### 候補例 😺🦐

* **ニュース分類（AG News など）** 😺🦐

  * 長めのニュース本文 → 要点抽出 → 要約 → カテゴリ分類、という流れが自然で、要約ステップの意味がわかりやすい😸🦐。

* **レビュー感情分類（Yelp / Amazon Polarity など）** 😺🦐

  * レビュー本文 → 要点抽出 → 要約 → ポジ/ネガなどの感情分類、という構成で、評価もしやすい😸🦐。

どちらでも実験の構造自体は同じなので、**最初は 1 つに絞り、数百〜数千サンプル程度で実験する**ことを想定している😺🦐。

---

## 5. モデル（エージェント）設計 😺🦐

### 5.1 ステップごとのエージェント構成 😺🦐

各ステップにつき 3 種類のエージェントを用意し、プロンプト／スタイル／前提とするフォーマットを変えることで、出力分布とタスク性能に差が生じるように設計する😺🦐。

* ステップ1：要点抽出エージェント `E1-A, E1-B, E1-C` 😺🦐
* ステップ2：要約エージェント `E2-A, E2-B, E2-C` 😺🦐
* ステップ3：分類エージェント `E3-A, E3-B, E3-C` 😺🦐

これにより、全体で **3 × 3 × 3 = 27 通り**のパイプライン（経路）が定義される😸🦐。

### 5.2 エージェント設計の具体方針（例）😺🦐

**ステップ1（要点抽出）** 😺🦐

* E1-A：情報漏れを最小化する冗長な bullet 抽出（多めにポイントを書く）😺🦐。
* E1-B：上位 3 点だけに絞る圧縮型の bullet 抽出😺🦐。
* E1-C：分類タスクで有効そうなキーワード（カテゴリ名に近い語など）を含めることを強調した bullet 抽出😺🦐。

**ステップ2（要約）** 😺🦐

* E2-A：人間向けの自然で滑らかな要約（可読性重視）😺🦐。
* E2-B：非常に短いがキーワード密度の高い 1 文要約😺🦐。
* E2-C：分類用テンプレートに沿った要約（例：「This text is about [TOPIC] because …」形式）😺🦐。

**ステップ3（分類）** 😺🦐

* E3-A：思考プロセス＋ラベルを出す説明的な分類😺🦐。
* E3-B：JSON 形式など、構造化された出力でラベルと信頼度を返す分類😺🦐。
* E3-C：入力が bullet あるいはテンプレート化された要約であることを強く前提にした分類（中間表現のフォーマット前提を変える）😺🦐。

これにより、各ステップのタスク性能だけでなく、ステップ間の「表現スタイル」「構造」「冗長さ」が異なるため、**中間表現の相性差**が顕在化しやすくなる😺🦐。

---

## 6. 実験プロトコル（作業手順）😺🦐

### 6.1 ログ収集フェーズ 😺🦐

選定したデータセットから N サンプル（例：N=500〜2000）を取り、**全 27 通りのパイプライン**を以下のように実行してログを収集する😺🦐。

各サンプル `x` について、すべての `(E1, E2, E3)` の組み合わせに対して次を実行する😺🦐。

1. `y1 = E1(x)`：要点抽出結果テキスト😺🦐。
2. `y2 = E2(y1)`：要約テキスト😺🦐。
3. `y3 = E3(y2)`：予測ラベル😺🦐。
4. 正解ラベル `gold_label` と `y3` を比較し、`is_correct ∈ {0,1}` を記録する😺🦐。

ログは行ベースで以下の情報を保存する（CSV など）😺🦐。

* `sample_id` 😺🦐
* `E1_id`（E1-A/B/C）😺🦐
* `E2_id`（E2-A/B/C）😺🦐
* `E3_id`（E3-A/B/C）😺🦐
* `y1_text`（ステップ1出力）😺🦐
* `y2_text`（ステップ2出力）😺🦐
* `pred_label`（ステップ3出力）😺🦐
* `gold_label` 😺🦐
* `is_correct`（0/1）😺🦐

### 6.2 集計フェーズ 😺🦐

1. **パイプラインごとの最終精度** 😺🦐

   * 各 `(E1,E2,E3)` について、`is_correct` の平均を取り、

     * `FinalAcc(E1,E2,E3)` を算出（27 個の値）😺🦐。

2. **ステップごとの“タスクスコア”**（簡易版）😺🦐

   * ステップ1モデル E1-k に対して：
     [
     TaskScore1(E1_k) = \text{平均}_{E2, E3} FinalAcc(E1_k, E2, E3)
     ]
     😺🦐。
   * ステップ2モデル E2-l に対して：
     [
     TaskScore2(E2_l) = \text{平均}_{E1, E3} FinalAcc(E1, E2_l, E3)
     ]
     😺🦐。
   * ステップ3モデル E3-m に対して：
     [
     TaskScore3(E3_m) = \text{平均}_{E1, E2} FinalAcc(E1, E2, E3_m)
     ]
     😺🦐。

3. **パイプラインのタスクスコア合成** 😺🦐

   * 各パイプラインに対して、
     [
     TaskScore(E1,E2,E3) = TaskScore1(E1) + TaskScore2(E2) + TaskScore3(E3)
     ]
     と定義する（重み付けなしの単純和、必要なら正規化や重み付けも検討）😺🦐。

---

## 7. 埋め込み距離の計算 😺🦐

### 7.1 埋め込みモデル 😺🦐

* 任意の文埋め込みモデル（Sentence-BERT 系など）を 1 つ選択し、

  * テキスト → 固定次元のベクトルへのマッピングを行う😺🦐。

### 7.2 ステップ1→2, 2→3 の距離 😺🦐

1. **ステップ1出力のモデル別分布** 😺🦐

   * 各サンプル・各 E1 について `y1_text` を埋め込み `e1(E1, sample)` を計算し、
   * モデルごとの平均ベクトル：
     [
     \mu^{(1)}*\text{out}(E1) = \text{平均}*{sample} e1(E1, sample)
     ]
     を求める😺🦐。

2. **ステップ2が“好む”入力分布** 😺🦐

   * E2 ごとに、「最も相性が良い E1」を
     [
     E1^* (E2) = \arg\max_{E1} FinalAcc(E1, E2, \cdot)
     ]
     のような基準で定める😺🦐。
   * そのペア `(E1^\*(E2), E2)` で生成された `y1_text` の埋め込みの平均を
     [
     \mu^{(2)}_\text{in}(E2)
     ]
     とする（= E2 にとって「理想的な入力分布」の代表）😺🦐。

3. **ステップ1→2 の距離** 😺🦐

   * コサイン距離などで
     [
     Dist_{1 \to 2}(E1,E2) = 1 - \cos\big(\mu^{(1)}*\text{out}(E1),\ \mu^{(2)}*\text{in}(E2)\big)
     ]
     を定義する（小さいほど相性が良い）😺🦐。

4. **ステップ2→3 も同様に計算** 😺🦐

   * ステップ2出力 `y2_text` の平均ベクトルから
     [
     \mu^{(2)}*\text{out}(E2),\ \mu^{(3)}*\text{in}(E3)
     ]
     を定義し、
     [
     Dist_{2 \to 3}(E2,E3) = 1 - \cos\big(\mu^{(2)}*\text{out}(E2),\ \mu^{(3)}*\text{in}(E3)\big)
     ]
     を同様に求める😺🦐。

5. **パイプライン全体の距離** 😺🦐

   * 各パイプライン `(E1,E2,E3)` について、
     [
     TotalDist(E1,E2,E3) = Dist_{1 \to 2}(E1,E2) + Dist_{2 \to 3}(E2,E3)
     ]
     を定義する😺🦐。

---

## 8. 戦略の定義と比較指標 😺🦐

### 8.1 戦略1：局所最強戦略（Baseline）😺🦐

* 各パイプラインに対して
  [
  LocalScore(E1,E2,E3) = TaskScore(E1,E2,E3)
  ]
  として、`LocalScore` が最大の `(E1_local, E2_local, E3_local)` を選択する😺🦐。
* この経路の最終精度を
  [
  FinalAcc_\text{local} = FinalAcc(E1_\text{local}, E2_\text{local}, E3_\text{local})
  ]
  とする😺🦐。

### 8.2 戦略2：ネットワーク最適戦略（距離込み）😺🦐

* 各パイプラインに対して
  [
  GraphScore(E1,E2,E3) = TaskScore(E1,E2,E3) - \lambda \cdot TotalDist(E1,E2,E3)
  ]
  を定義する（λ > 0 はハイパーパラメータ）😺🦐。
* `GraphScore` が最大の `(E1_graph, E2_graph, E3_graph)` を選択し、その最終精度を
  [
  FinalAcc_\text{graph} = FinalAcc(E1_\text{graph}, E2_\text{graph}, E3_\text{graph})
  ]
  とする😺🦐。

### 8.3 主たる比較 😺🦐

* `FinalAcc_graph` と `FinalAcc_local` を比較し、

  * `FinalAcc_graph > FinalAcc_local` であれば、

    * 「距離込みのネットワーク最適戦略が、局所最強戦略よりも全体性能で優れる」
    * もしくは、同等性能で距離が小さい経路を選べているかどうかを確認する😺🦐。

---

## 9. タスクスコア vs 距離のトレードオフ解析 😺🦐

### 9.1 散布図とパレートフロンティア 😺🦐

* 各パイプラインを 2 次元平面上の点として可視化する😺🦐。

  * 横軸：`TotalDist(E1,E2,E3)`（小さいほどステップ間の相性が良い）😺🦐。
  * 縦軸：`TaskScore(E1,E2,E3)` または `FinalAcc(E1,E2,E3)`（大きいほどタスク性能が高い）😺🦐。
* この点群に対して、

  * 「これ以上距離を減らすとスコアが下がり、スコアを上げると距離が増える」という
    **パレートフロンティア（トレードオフ曲線）**を抽出・描画する😺🦐。

### 9.2 線を使った読み方（タスク優先 / 距離優先）😺🦐

* **タスクスコア優先（ほぼ最高精度を維持しつつ距離を最小化）** 😺🦐

  * 縦軸の高い位置（最大スコア付近）に水平線を引き、その線に近い中で最も左側（距離が小さい）点を見ることで、

    * 「精度をほとんど落とさずに、どこまで距離を削れるか」を評価する😺🦐。

* **距離優先（相性の良さを維持しつつ精度を最大化）** 😺🦐

  * 横軸で距離の小さい位置に縦線を引き、その線の近くで最も上側（スコアが高い）点を見ることで、

    * 「距離を少しだけ緩めることで、どこまで精度が伸ばせるか」を評価する😺🦐。

* `GraphScore = TaskScore − λ·TotalDist` の観点からは、

  * λ を変えることは「傾き λ の直線を動かし、フロンティアに接する点（最適経路）を変える」操作として幾何的に解釈できる😺🦐。

---

## 10. 期待されるアウトカム 😺🦐

* マルチステップ LLM パイプラインにおいて、

  * 「各ステップ単独のタスクスコアの和」で選んだ経路と、
  * 「タスクスコアと埋め込み距離のトレードオフ」で選んだ経路を比較し、
  * 後者のほうが

    * **同等以上の最終精度で、より小さい距離（相性の良い表現遷移）を持つ**、
    * あるいは **わずかな距離増加で大きく精度が向上する“甘いポイント”が存在する**
      ことが示されれば、埋め込み空間上のネットワーク構造を考慮したエージェント選択の有効性を主張できる😺🦐。

* また、得られたトレードオフ曲線や、局所最強戦略とネットワーク最適戦略が平面上のどこに位置するか可視化することで、

  * 「なぜその経路を選ぶべきなのか」という説明可能性も向上し、
  * 今後のエージェントルーティング・サービスディスカバリ（AgentDNS 的な世界）への接続もしやすくなると期待される😺🦐。

---
